{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32af0822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IoU between img vs polygon: 0.9660969036924436\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random  # 데이터 섞기를 위한 라이브러리\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "iou_scores=[]\n",
    "def create_new_data_directory(original_data_dir, new_data_dir, split_ratio=0.8):\n",
    "    # Ensure the new data directory exists\n",
    "    if not os.path.exists(new_data_dir):\n",
    "        os.makedirs(new_data_dir)\n",
    "\n",
    "    # Define paths for images and labels\n",
    "    new_images_dir = os.path.join(new_data_dir, 'images')\n",
    "    new_labels_dir = os.path.join(new_data_dir, 'labels')\n",
    "\n",
    "    # Create train and val directories\n",
    "    for subdir in ['train', 'val']:\n",
    "        os.makedirs(os.path.join(new_images_dir, subdir), exist_ok=True)\n",
    "        os.makedirs(os.path.join(new_labels_dir, subdir), exist_ok=True)\n",
    "\n",
    "    # List all image files and label files\n",
    "    def list_files(base_dir):\n",
    "        image_files = []\n",
    "        label_files = []\n",
    "        for cityname in os.listdir(base_dir):\n",
    "            img_dir = os.path.join(base_dir, cityname, 'img')\n",
    "            label_dir = os.path.join(base_dir, cityname, 'new_txt')\n",
    "            if os.path.exists(img_dir) and os.path.exists(label_dir):\n",
    "                for img_file in os.listdir(img_dir):\n",
    "                    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        image_files.append(os.path.join(img_dir, img_file))\n",
    "                        label_file = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "                        if os.path.exists(label_file):\n",
    "                            label_files.append(label_file)\n",
    "        return list(zip(image_files, label_files))\n",
    "\n",
    "    # Get all files and shuffle them\n",
    "    all_files = list_files(os.path.join(original_data_dir, 'train'))\n",
    "    random.shuffle(all_files)  # 섞기\n",
    "\n",
    "    # Split files into train and validation sets\n",
    "    split_index = int(len(all_files) * split_ratio)\n",
    "    train_files = all_files[:split_index]\n",
    "    val_files = all_files[split_index:]\n",
    "\n",
    "    # Copy files for both train and validation sets\n",
    "    copy_and_rename_files(train_files, 'train', new_images_dir, new_labels_dir)\n",
    "    copy_and_rename_files(val_files, 'val', new_images_dir, new_labels_dir)\n",
    "\n",
    "def copy_and_rename_files(files, split_type, new_images_dir, new_labels_dir):\n",
    "    txt_file_path = os.path.join(new_data_dir, f'{split_type}.txt')\n",
    "    with open(txt_file_path, 'w') as txt_file:\n",
    "        for image_path, label_path in files:\n",
    "            # Safely split the path\n",
    "            path_parts = os.path.normpath(image_path).split(os.sep)\n",
    "\n",
    "            # Generate a unique ID\n",
    "            if len(path_parts) >= 3:\n",
    "                unique_id = f\"{path_parts[-3]}_{path_parts[-1].split('.')[0]}\"\n",
    "            else:\n",
    "                unique_id = path_parts[-1].split('.')[0]\n",
    "\n",
    "            # Create new paths for image and label files\n",
    "            img_ext = os.path.splitext(image_path)[1]\n",
    "            new_image_name = f'{unique_id}{img_ext}'\n",
    "            dest_image_path = os.path.join(new_images_dir, split_type, new_image_name)\n",
    "\n",
    "            # Copy image file\n",
    "            shutil.copy(image_path, dest_image_path)\n",
    "\n",
    "            # Copy and reformat label file\n",
    "            new_label_name = f'{unique_id}.txt'\n",
    "            dest_label_path = os.path.join(new_labels_dir, split_type, new_label_name)\n",
    "            reformat_label_file(label_path, dest_label_path, image_path)\n",
    "\n",
    "            # Write the new image path to the txt file\n",
    "            txt_file.write(dest_image_path + '\\n')\n",
    "\n",
    "def reformat_label_file(src_label_path, dest_label_path, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    mask_dir = os.path.join(os.path.dirname(image_path), '..', 'instance')\n",
    "    mask_path = os.path.join(mask_dir, os.path.basename(image_path))\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if mask is None:\n",
    "        print(f\"Warning: Mask not found for {image_path}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    with open(src_label_path, 'r') as src_file:\n",
    "        lines = src_file.readlines()\n",
    "    with open(dest_label_path, 'w') as dest_file:\n",
    "        for line_num, line in enumerate(lines):\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 10:\n",
    "                x1, y1, x2, y2, class_id, loc_id, brake, incatlft, incatrht, hazlit = map(float, parts[:10])\n",
    "\n",
    "                instance_mask = np.zeros_like(mask)\n",
    "                instance_mask[mask == int(line_num)] = 255\n",
    "\n",
    "                new_instance_mask = remove_noise(instance_mask)\n",
    "                polygons = mask2polygon(new_instance_mask)\n",
    "                recreated_mask = recreate_mask_from_polygons(polygons, instance_mask.shape)\n",
    "\n",
    "                iou_score = calculate_iou(instance_mask, recreated_mask)\n",
    "                if iou_score > 0.01:\n",
    "                    iou_scores.append(iou_score)\n",
    "\n",
    "                    normalized_contours = []\n",
    "                    for polygon in polygons:\n",
    "                        normalized_contours.extend([\n",
    "                            (polygon[i] / width if i % 2 == 0 else polygon[i] / height)\n",
    "                            for i in range(len(polygon))\n",
    "                        ])\n",
    "                    new_label_line = f'{int(class_id)} {int(loc_id)} {int(brake)} {int(incatlft)} {int(incatrht)} {int(hazlit)} ' + ' '.join(map(str, normalized_contours))\n",
    "                    dest_file.write(new_label_line + '\\n')\n",
    "\n",
    "def mask2polygon(image, mode=cv2.CHAIN_APPROX_TC89_KCOS):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_CCOMP, mode)\n",
    "    polygons = [contour.flatten().tolist() for contour in contours if len(contour) >= 3]\n",
    "    return polygons\n",
    "\n",
    "def remove_noise(mask):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    return mask\n",
    "\n",
    "def calculate_iou(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def recreate_mask_from_polygons(polygons, size):\n",
    "    mask = np.zeros(size, dtype=np.uint8)\n",
    "    for polygon in polygons:\n",
    "        contour = np.array(polygon).reshape((-1, 2))\n",
    "        cv2.fillPoly(mask, [contour], 255)\n",
    "    return mask\n",
    "\n",
    "# Run the script\n",
    "original_data_dir = './'\n",
    "new_data_dir = './processed_data'\n",
    "create_new_data_directory(original_data_dir, new_data_dir, split_ratio=0.8)\n",
    "\n",
    "# Calculate and print average IoU\n",
    "if len(iou_scores) > 0:\n",
    "    avg_iou = sum(iou_scores) / len(iou_scores)\n",
    "    print(f\"Average IoU between img vs polygon: {avg_iou}\")\n",
    "else:\n",
    "    print(\"No IoU scores available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f8a06-7c17-444a-8242-9cb3dad2d75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
